{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joshua Kyle K. Entrata\n",
    "4CSC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing a Sentence\n",
    "\n",
    "Lets start small. What can we learn about a sentence?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('all')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Preamble\n",
    "#\n",
    "\n",
    "# Import our core libraries\n",
    "import re\n",
    "\n",
    "# Read in the documents we will use\n",
    "from nltk.corpus import reuters\n",
    "coffee = reuters.open('test/19570').read()\n",
    "gold = reuters.open('test/16589').read()\n",
    "\n",
    "text = gold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation and Tokenization\n",
    "\n",
    "The first step for us to do is to actually get a sentence from the document we loaded. The general process of extracting _meaningful units_ of text from a larger text is called **segmentation**.\n",
    "\n",
    "When applied to finding smaller word-like units from text, the process is often referred to as **tokenization** (and you may find these terms used interchangeably).\n",
    "\n",
    "A _meaningful unit_ is anything that is useful for your application, these can be _sections_ of a document, _paragraphs_, _words_ or in our case _sentences_.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"HOMESTAKE &lt;HM> MULLS BUYING ORE RESERVES\\n  Homestake Mining Co is considering\\n  acquiring more gold ore reserves in addition to the company's\\n  exploration efforts, chief executive Harry Conger told Reuters\\n  in an interview\",\n",
       " '\\n      \"We are looking at more options to acquire more reserves\\n  rather than just exploration,\" Conger said adding, \"the move to\\n  consider acquisitions represents a change in the company\\'s\\n  acquisitions policy',\n",
       " '\"\\n      Conger said all of Homestake\\'s current cash position of 120\\n  mln dlrs would be available to acquire reserves',\n",
       " ' In addition,\\n  Homestake has two lines of credit totaling 150 mln dlrs which\\n  have not been drawn on today and could be used to finance an\\n  acquisition, he said',\n",
       " '\\n      Conger said he anticipates 1987 exploration budget will be\\n  about the same as 1986 spending of 27',\n",
       " '3 mln dlrs',\n",
       " \" Conger said\\n  exploration for precious metals may be slightly higher than\\n  last year's spending of 17\",\n",
       " \"7 mln dlrs while oil and gas\\n  exploration spending will be slightly less than last year's 9\",\n",
       " '6\\n  pct',\n",
       " \"\\n      Conger said he sees Homestake's 1987 gold production about\\n  the same as 1986 gold production of 669,594 ounces\"]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple sentence segmentation\n",
    "\n",
    "#\n",
    "# Using string.split\n",
    "#\n",
    "sentences = text.split('.')\n",
    "sentences[0:10]\n",
    "\n",
    "# Q1: Are there any issues with this approach?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"HOMESTAKE &lt;HM> MULLS BUYING ORE RESERVES\\n  Homestake Mining Co is considering\\n  acquiring more gold ore reserves in addition to the company's\\n  exploration efforts, chief executive Harry Conger told Reuters\\n  in an interview\",\n",
       " '\\n      \"We are looking at more options to acquire more reserves\\n  rather than just exploration,\" Conger said adding, \"the move to\\n  consider acquisitions represents a change in the company\\'s\\n  acquisitions policy',\n",
       " '\"\\n      Conger said all of Homestake\\'s current cash position of 120\\n  mln dlrs would be available to acquire reserves',\n",
       " ' In addition,\\n  Homestake has two lines of credit totaling 150 mln dlrs which\\n  have not been drawn on today and could be used to finance an\\n  acquisition, he said',\n",
       " '\\n      Conger said he anticipates 1987 exploration budget will be\\n  about the same as 1986 spending of 27',\n",
       " '3 mln dlrs',\n",
       " \" Conger said\\n  exploration for precious metals may be slightly higher than\\n  last year's spending of 17\",\n",
       " \"7 mln dlrs while oil and gas\\n  exploration spending will be slightly less than last year's 9\",\n",
       " '6\\n  pct',\n",
       " \"\\n      Conger said he sees Homestake's 1987 gold production about\\n  the same as 1986 gold production of 669,594 ounces\"]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Using re.split\n",
    "#\n",
    "sentences = re.split(r'[\\.\\?!]', text)\n",
    "sentences[0:10]\n",
    "\n",
    "# Q2: How about now? What other corner cases and caveats might \n",
    "#    we want to stay aware of?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"HOMESTAKE &lt;HM> MULLS BUYING ORE RESERVES\\n  Homestake Mining Co is considering\\n  acquiring more gold ore reserves in addition to the company's\\n  exploration efforts, chief executive Harry Conger told Reuters\\n  in an interview.\",\n",
       " '\"We are looking at more options to acquire more reserves\\n  rather than just exploration,\" Conger said adding, \"the move to\\n  consider acquisitions represents a change in the company\\'s\\n  acquisitions policy.\"',\n",
       " \"Conger said all of Homestake's current cash position of 120\\n  mln dlrs would be available to acquire reserves.\",\n",
       " 'In addition,\\n  Homestake has two lines of credit totaling 150 mln dlrs which\\n  have not been drawn on today and could be used to finance an\\n  acquisition, he said.',\n",
       " 'Conger said he anticipates 1987 exploration budget will be\\n  about the same as 1986 spending of 27.3 mln dlrs.',\n",
       " \"Conger said\\n  exploration for precious metals may be slightly higher than\\n  last year's spending of 17.7 mln dlrs while oil and gas\\n  exploration spending will be slightly less than last year's 9.6\\n  pct.\",\n",
       " \"Conger said he sees Homestake's 1987 gold production about\\n  the same as 1986 gold production of 669,594 ounces.\",\n",
       " \"However, 1987 first quarter production from its McLaughlin\\n  reserve will be about 10 pct lower than last year's 45,400\\n  ounces due to start-up production problems.\",\n",
       " 'He said he believes gold prices will hold above the 400\\n  U.S. dlr an ounce level for the rest of 1987.',\n",
       " 'IN 1986, company earnings were based an average market\\n  price for gold of 368 dlrs an ounce.']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "# Using NLTK.\n",
    "# \n",
    "\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "sentences[0:10]\n",
    "\n",
    "# Notice that this retains the punctuation in the sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The quick brown fox jumped over Mr. Jones.',\n",
       " 'Much to the disapproval of the dogs.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLTK will also handle cases like Mr. Jones correctly.\n",
    "with_salutations = \"\"\"The quick brown fox jumped over Mr. Jones.\n",
    "                      Much to the disapproval of the dogs.\"\"\"\n",
    "nltk.sent_tokenize(with_salutations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Tokenization\n",
    "\n",
    "We can apply the same approach to finding word-like units of text. All the above methods could be used but similar caveats will apply. So lets jump straight into using nltk for the tokenization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The : 3\n",
      "quick : 5\n",
      "brown : 5\n",
      "fox : 3\n",
      "jumped : 6\n",
      "over : 4\n",
      "Mr. : 3\n",
      "Jones : 5\n",
      ". : 1\n",
      "Much : 4\n",
      "to : 2\n",
      "the : 3\n",
      "disapproval : 11\n",
      "of : 2\n",
      "the : 3\n",
      "dogs : 4\n",
      ". : 1\n"
     ]
    }
   ],
   "source": [
    "# We first need to tokenize our sentence into smaller units, in our case words.\n",
    "with_salutations = \"\"\"The quick brown fox jumped over Mr. Jones.\n",
    "                      Much to the disapproval of the dogs.\"\"\"\n",
    "words = nltk.word_tokenize(with_salutations)\n",
    "\n",
    "# Lets print out all the things in this list and the lengths of the words\n",
    "# Notice that python is whitespace sensitive with indentation\n",
    "# indicating block structure.\n",
    "for word in words:\n",
    "    word_len = len(word)\n",
    "    print(word + ' : ' + str(word_len))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Your Turn!**\n",
    "\n",
    "Plot the lengths of all the sentences in the **gold** article.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence lengths: [228, 207, 110, 163, 110, 204, 112, 165, 103, 93, 230]\n",
      "\n",
      "ASCII Bar Graph of Sentence Lengths:\n",
      "\n",
      "************************************************************************************************************************************************************************************************************************************\n",
      "\n",
      "***************************************************************************************************************************************************************************************************************\n",
      "\n",
      "**************************************************************************************************************\n",
      "\n",
      "*******************************************************************************************************************************************************************\n",
      "\n",
      "**************************************************************************************************************\n",
      "\n",
      "************************************************************************************************************************************************************************************************************\n",
      "\n",
      "****************************************************************************************************************\n",
      "\n",
      "*********************************************************************************************************************************************************************\n",
      "\n",
      "*******************************************************************************************************\n",
      "\n",
      "*********************************************************************************************\n",
      "\n",
      "**************************************************************************************************************************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1\n",
    "# Plot the lengths of all the sentences in the __gold__ article.\n",
    "# First print them and then see if you can make an ascii bar chart of them.\n",
    "# It could look something like this...\n",
    "#\n",
    "# ****\n",
    "# ******************\n",
    "# ***********\n",
    "#\n",
    "\n",
    "gold = reuters.open('test/16589').read()\n",
    "sentences = nltk.sent_tokenize(gold)\n",
    "\n",
    "# Step one. Find all the lengths and print them to the console/notebook.\n",
    "sentence_lengths = [len(sentence) for sentence in sentences]\n",
    "print(\"Sentence lengths:\", sentence_lengths)\n",
    "\n",
    "# Step two (extra credit). Make an horizontal ascii bar graph of the numbers \n",
    "print(\"\\nASCII Bar Graph of Sentence Lengths:\")\n",
    "for length in sentence_lengths:\n",
    "    print('\\n' + '*' * length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parts of Speech\n",
    "\n",
    "What else can we find out about this sentence. We can look for specific patterns we have already identified, but we can also try and deduce what type of this word this is, e.g. is it a noun or a verb.\n",
    "\n",
    "This activity is known as **Part of Speech Tagging** _(POS Tagging)_, and a number of algorithms have been developed to do this, some are statistical and others are rule based.\n",
    "\n",
    "Lets look at how we can do this in nltk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOMESTAKE &lt;HM> MULLS BUYING ORE RESERVES\n",
      "  Homestake Mining Co is considering\n",
      "  acquiring more gold ore reserves in addition to the company's\n",
      "  exploration efforts, chief executive Harry Conger told Reuters\n",
      "  in an interview.\n"
     ]
    }
   ],
   "source": [
    "# Lets look at the first sentence of the article\n",
    "sentence = sentences[0]\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HOMESTAKE',\n",
       " '&',\n",
       " 'lt',\n",
       " ';',\n",
       " 'HM',\n",
       " '>',\n",
       " 'MULLS',\n",
       " 'BUYING',\n",
       " 'ORE',\n",
       " 'RESERVES',\n",
       " 'Homestake',\n",
       " 'Mining',\n",
       " 'Co',\n",
       " 'is',\n",
       " 'considering',\n",
       " 'acquiring',\n",
       " 'more',\n",
       " 'gold',\n",
       " 'ore',\n",
       " 'reserves',\n",
       " 'in',\n",
       " 'addition',\n",
       " 'to',\n",
       " 'the',\n",
       " 'company',\n",
       " \"'s\",\n",
       " 'exploration',\n",
       " 'efforts',\n",
       " ',',\n",
       " 'chief',\n",
       " 'executive',\n",
       " 'Harry',\n",
       " 'Conger',\n",
       " 'told',\n",
       " 'Reuters',\n",
       " 'in',\n",
       " 'an',\n",
       " 'interview',\n",
       " '.']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We first need to tokenize our sentence into smaller units, in our case words.\n",
    "words = nltk.word_tokenize(sentence)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note that the result includes punctuation as tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('HOMESTAKE', 'NNP'),\n",
       " ('&', 'CC'),\n",
       " ('lt', 'NN'),\n",
       " (';', ':'),\n",
       " ('HM', 'NNP'),\n",
       " ('>', 'NNP'),\n",
       " ('MULLS', 'NNP'),\n",
       " ('BUYING', 'NNP'),\n",
       " ('ORE', 'NNP'),\n",
       " ('RESERVES', 'NNP'),\n",
       " ('Homestake', 'NNP'),\n",
       " ('Mining', 'NNP'),\n",
       " ('Co', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('considering', 'VBG'),\n",
       " ('acquiring', 'VBG'),\n",
       " ('more', 'JJR'),\n",
       " ('gold', 'NN'),\n",
       " ('ore', 'NN'),\n",
       " ('reserves', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('addition', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('company', 'NN'),\n",
       " (\"'s\", 'POS'),\n",
       " ('exploration', 'NN'),\n",
       " ('efforts', 'NNS'),\n",
       " (',', ','),\n",
       " ('chief', 'JJ'),\n",
       " ('executive', 'NN'),\n",
       " ('Harry', 'NNP'),\n",
       " ('Conger', 'NNP'),\n",
       " ('told', 'VBD'),\n",
       " ('Reuters', 'NNP'),\n",
       " ('in', 'IN'),\n",
       " ('an', 'DT'),\n",
       " ('interview', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we have the words we can use nltk's POS tagger\n",
    "\n",
    "tagged = nltk.pos_tag(words)\n",
    "tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These tags like NN and NNP come from a standardized set of tags known as the **Penn Treebank POS Tags**\n",
    "\n",
    "You can see the full list here https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lets extract all the nouns from all the sentences in the document\n",
    "\n",
    "# Will return all the words in the words input param that match a given tag.\n",
    "def get_tagged(words, tag):\n",
    "    tagged = nltk.pos_tag(words)\n",
    "\n",
    "    matches = []\n",
    "    for tup in tagged:\n",
    "        if tup[1] == tag:\n",
    "            matches.append(tup)\n",
    "    return matches\n",
    "\n",
    "# This is the same function as above, but uses a List Comprehension\n",
    "def get_tagged(words, tag):\n",
    "    tagged = nltk.pos_tag(words)\n",
    "    return [tup for tup in tagged if tup[1] == tag]\n",
    "\n",
    "# Will word tokenize a list of sentence and return those tokens\n",
    "def tokenize(sentences):\n",
    "    return [nltk.word_tokenize(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenized = tokenize(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('HOMESTAKE', 'NNP'),\n",
       "  ('HM', 'NNP'),\n",
       "  ('>', 'NNP'),\n",
       "  ('MULLS', 'NNP'),\n",
       "  ('BUYING', 'NNP'),\n",
       "  ('ORE', 'NNP'),\n",
       "  ('RESERVES', 'NNP'),\n",
       "  ('Homestake', 'NNP'),\n",
       "  ('Mining', 'NNP'),\n",
       "  ('Co', 'NNP'),\n",
       "  ('Harry', 'NNP'),\n",
       "  ('Conger', 'NNP'),\n",
       "  ('Reuters', 'NNP')],\n",
       " [('Conger', 'NNP')],\n",
       " [('Conger', 'NNP'), ('Homestake', 'NNP')],\n",
       " [('Homestake', 'NNP')],\n",
       " [('Conger', 'NNP')],\n",
       " [('Conger', 'NNP')],\n",
       " [('Conger', 'NNP'), ('Homestake', 'NNP')],\n",
       " [('McLaughlin', 'NNP')],\n",
       " [('U.S.', 'NNP')],\n",
       " [],\n",
       " [('Conger', 'NNP')]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnps = [get_tagged(tokens, 'NNP') for tokens in tokenized]\n",
    "nnps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see. POS Tagging takes a little bit of time. It can also yield imperfect results. However it can be an interesting approach to finding out more about a text.\n",
    "\n",
    "It is also useful to keep in mind that there are actually a number of different algorithms and models that can be used for POS tagging.\n",
    "\n",
    "See http://www.nltk.org/book/ch05.html and http://www.nltk.org/api/nltk.tag.html for a reference to what is in NLTK.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Your Turn!**\n",
    "\n",
    "Plot the number of verbs (VB, VBD, VBG, VBN, VBP) across all sentences in the gold article. Which sentence has the most number of verbs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: 4 verbs\n",
      "Sentence 2: 7 verbs\n",
      "Sentence 3: 3 verbs\n",
      "Sentence 4: 9 verbs\n",
      "Sentence 5: 3 verbs\n",
      "Sentence 6: 3 verbs\n",
      "Sentence 7: 2 verbs\n",
      "Sentence 8: 1 verbs\n",
      "Sentence 9: 4 verbs\n",
      "Sentence 10: 2 verbs\n",
      "Sentence 11: 6 verbs\n",
      "\n",
      "Sentence 4 has the most verbs with 9 verbs.\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2\n",
    "# Count the number of verbs (VB) in each sentence of the gold article\n",
    "# You may want to make some helper functions.\n",
    "\n",
    "# Helper function to count verbs in a POS-tagged sentence\n",
    "def count_verbs(tagged_sentence):\n",
    "    return sum(1 for _, tag in tagged_sentence if tag.startswith('VB'))\n",
    "\n",
    "gold = reuters.open('test/16589').read()\n",
    "\n",
    "\n",
    "# Step 1. Tokenize the article to sentences\n",
    "sentences = nltk.sent_tokenize(gold)\n",
    "\n",
    "# Step 2. For each sentence tokenize to words and store that list\n",
    "verb_counts = []\n",
    "for sentence in sentences:\n",
    "    words = nltk.word_tokenize(sentence) \n",
    "    tagged_words = nltk.pos_tag(words)    \n",
    "    verb_count = count_verbs(tagged_words)  \n",
    "    verb_counts.append(verb_count)\n",
    "\n",
    "# Step 3. POS tag all the tokens in each sentence and filter out non verb tokens.\n",
    "for i, count in enumerate(verb_counts):\n",
    "    print(f\"Sentence {i + 1}: {count} verbs\")\n",
    "\n",
    "# Step 4. Print out the counts for each sentence. Which sentence has the most verbs\n",
    "max_verbs = max(verb_counts)\n",
    "max_index = verb_counts.index(max_verbs)\n",
    "print(f\"\\nSentence {max_index + 1} has the most verbs with {max_verbs} verbs.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "One way we can think of what we have been just been doing is finding _'things'_ that give some information about our sentences. Features cound be anything countable, whether it is is the amount of money mentioned in a sentence, or the number of characters. A big part of text analysis, particularly the statistical and pattern based approaches we will be looking at is feature selection and extraction.\n",
    "\n",
    "Q3: What other features could you think to extract from a sentence?\n",
    "\n",
    "# Examples\n",
    "\n",
    "We can also see how even simple seeming features can be used to good effect in building visualizations.\n",
    "\n",
    "[Listening Post](https://vimeo.com/3885443) by Mark Hansen and Ben Rubin is an installation that displays sentence gathered from the internet that contain phrases like \"I am\" or \"I love.\"\n",
    "\n",
    "[We Feel Fine](http://wefeelfine.org/) by Jonathan Harris and Sep Kamvar begins by searching for blog posts that containt phrases like \"I am feeling\", \"I feel\" ... [Regex]\n",
    "\n",
    "[Stereotropes](http://stereotropes.bocoup.com/) by Bocoup uses POS tagging to extract adjectives from text to then visualize descriptions of characters in film. [POS Tagging]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
